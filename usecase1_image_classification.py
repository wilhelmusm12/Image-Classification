# -*- coding: utf-8 -*-
"""UseCase2_Image_Classification_Wilhelmus_Medhavi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RZnXmY9XW518a0diPVzoD1BkO_JJMrx9
"""

# Commented out IPython magic to ensure Python compatibility.
# NOTE : Please use GPU for runtime type hardware accelerator

import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf
import zipfile
import os
import shutil
from tensorflow import keras
from google.colab import files
from tensorflow.keras import layers, regularizers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# %matplotlib inline

print(tf.__version__)

# Upload kaggle.json
files.upload()

# Set up Kaggle API
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d duttadebadri/image-classification

# Unzip dataset
with zipfile.ZipFile('image-classification.zip', 'r') as zip_ref:
    zip_ref.extractall('dataset')

# Cek path directory
base_dir = 'dataset'
train_dir = os.path.join(base_dir, 'images')
val_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

print("Base directory is:", base_dir)
print(os.listdir(base_dir))

# Define path untuk train, test, dan validasi

# Base paths
train_dir = 'dataset/images/images'
val_dir = 'dataset/validation/validation'
test_dir_predict = 'dataset/test/test/classify'  # For backtesting (no labels)

print("Train classes:", os.listdir(train_dir))
print("Validation classes:", os.listdir(val_dir))
print("Test images for prediction:", os.listdir(test_dir_predict))

# Hitung jumlah gambar pada setiap kelas data train
data_train_path = 'dataset/images/images'

# Count number of images per class
image_count = {}

for class_name in os.listdir(data_train_path):
    class_path = os.path.join(data_train_path, class_name)
    if os.path.isdir(class_path):
        num_images = len(os.listdir(class_path))
        image_count[class_name] = num_images
        print(f"Class '{class_name}': {num_images} images")

# Hitung jumlah gambar pada setiap kelas data test
data_train_path = 'dataset/validation/validation'

# Count number of images per class
image_count = {}

for class_name in os.listdir(data_train_path):
    class_path = os.path.join(data_train_path, class_name)
    if os.path.isdir(class_path):
        num_images = len(os.listdir(class_path))
        image_count[class_name] = num_images
        print(f"Class '{class_name}': {num_images} images")

# Define Image generators
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

val_datagen = ImageDataGenerator(rescale=1./255)


# Load data train dan validasi dari direktori
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

# Check data label kelas hasil read

print('train: {}'.format(train_generator.class_indices))
print('val: {}'.format(val_generator.class_indices))

# Karena terdapat typo maka perlu diperbaiki untuk train
# data akan mengikuti validasi

train_base = 'dataset/images/images'
rename_dict = {
    'architecure': 'architecture',
    'food and d rinks': 'food',
    'travel and  adventure': 'travel and adventure'
}

for wrong_name, correct_name in rename_dict.items():
    wrong_path = os.path.join(train_base, wrong_name)
    correct_path = os.path.join(train_base, correct_name)

    if os.path.exists(wrong_path):
        os.rename(wrong_path, correct_path)
        print(f"Renamed '{wrong_name}' to '{correct_name}'")
    else:
        print(f"'{wrong_name}' not found, skipping...")

# Define ulang train generator agar tebaca dengan benar

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Load data train dari direktori
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)


# Check data label kelas kembali

print('train: {}'.format(train_generator.class_indices))
print('val: {}'.format(val_generator.class_indices))

# Define model deep learning CNN untuk klasifikasi label gambar

def model_dl():
    model = tf.keras.Sequential()
    model.add(layers.InputLayer(input_shape=(150, 150, 3)))
    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(256, activation='relu',
                           kernel_regularizer=regularizers.l2(0.001)))
    model.add(layers.Dropout(0.3))
    model.add(layers.Dense(4, activation='softmax'))
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model

model = model_dl()
model.summary()

# Fitting Model deep learning
# Harapan akurasi model diatas 80%

model.fit(
      train_generator,
      epochs=25,
      validation_data=val_generator,
      verbose=1)

# Label klasifikasi gambar

print('train: {}'.format(train_generator.class_indices))
print('val: {}'.format(val_generator.class_indices))

# Fungsi untuk memuat gambar dan melakukan preprocessing
def load_and_preprocess_image(image_path, target_size=(150, 150)):
    img = image.load_img(image_path, target_size=target_size)
    img_array = image.img_to_array(img) / 255.0  # Normalisasi gambar
    return np.expand_dims(img_array, axis=0)  # Tambahkan dimensi batch (batch_size=1)

# Direktori gambar test
test_dir = 'dataset/test/test/classify'
class_labels = {0: 'architecture', 1: 'art and culture', 2: 'food', 3: 'travel and adventure'}

# Daftar untuk menyimpan gambar dan label prediksi
images = []
predictions = []
filenames = []

# Loop untuk membaca gambar dalam folder dan melakukan prediksi
for filename in os.listdir(test_dir):
    image_path = os.path.join(test_dir, filename)
    img = load_and_preprocess_image(image_path)
    filenames.append(filename)

    # Lakukan prediksi
    pred = model.predict(img)

    # Prediksi untuk batch pertama (batch size=1)
    predicted_class_index = np.argmax(pred, axis=1)[0]
    predicted_class_label = class_labels[predicted_class_index]

    predictions.append((predicted_class_index, predicted_class_label))
    images.append(image.load_img(image_path, target_size=(150, 150)))

# Tampilkan gambar dan prediksi
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
axes = axes.ravel()

for i in range(10):
    axes[i].imshow(images[i])
    predicted_class_index, predicted_class_label = predictions[i]
    axes[i].set_title(f"Pred: {predicted_class_label} ({predicted_class_index})")
    axes[i].axis('off')

plt.tight_layout()
plt.show()

# Berdasarkan hasil prediksi dari folder test tersebut, model masih belum dapat mengklasifikasikan dengan baik
# kesepuluh gambar tersebut adalah gambar 'travel and adventure'
# hanya 3/10 yang benar, oleh karena itu akan dicoba upload mandiri sebagai tes pengecekan masing2 kelas

# Upload gambar manual, untuk eksperimen

uploaded = files.upload()
label_mapping = train_generator.class_indices

# Membalik dictionary: {0: 'architecture', ...}
label_mapping = {v: k for k, v in label_mapping.items()}

# Fungsi untuk dapatkan nama label dari prediksi
def get_label_name(class_idx):
    return label_mapping.get(class_idx, "Label tidak ditemukan")

# Prediksi
for fn in uploaded.keys():
    # Load gambar
    img = image.load_img(fn, target_size=(150, 150))
    plt.imshow(img)
    plt.axis('off')
    plt.show()
    x = image.img_to_array(img) / 255.0
    x = np.expand_dims(x, axis=0)

    pred = model.predict(x)
    class_idx = np.argmax(pred, axis=1)[0]
    label_name = get_label_name(class_idx)
    print(f"File: {fn} --> Prediksi: {label_name} (class {class_idx})")

# Model dapat memprediksi 2/4 dari gambar manual yang diberikan
# Model masih kesulitan saat memprediksi architecture dan food, dan kebanyakan diprediksi menjadi art & culture
# Perlu lebih banyak sample data train untuk meningkatan akurasi klasifikasi gambar, dan mengurangi sample train yang terlihat ambigu